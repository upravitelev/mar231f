[["index.html", "Методы анализа больших данных в исследованиях поведения покупателей Intro", " Методы анализа больших данных в исследованиях поведения покупателей Ph.A.Upravitelev 2024-11-07 Intro September 9: О курсе + задачи продуктовых аналитиков. Знакомство. Структура курса. Организационная информация по курсу. Виды аналитиков. Продукт, продуктовая аналитика. Роли продуктовых аналитиков в командах. Грейды. Этапы развития продукта и задачи аналитиков на каждом этапе. Бизнес-модели. "],["c1_intro.html", "О курсе и аналитиках Запись занятия Обо мне Contacts О курсе Виды аналитиков Продуктовая аналитика Стадии развития продукта Бизнес-модели Полезные материалы Домашнее задание", " О курсе и аналитиках Запись занятия Обо мне продуктовый аналитик в Pixonic продуктовый аналитик в GameInsight аналитик в Консультант+ аспирант СПбГУ (когнитивная психология) Contacts @konhis в telegram upravitelev@gmail.com (дополнительное средство коммуникации) О курсе основные темы Введение в цели и задачи продуктовой аналитики Метрики активности и вовлечения пользователей Основы юнит-экономики и метрики монетизации пользователей Проверка гипотез А/B-тесты дополнительные темы SQL разметка событий дашборды приглашенные лекторы (UX, аналитика) разбор кейсов формы контроля две контрольные работы две домашние работы накопительная оценка по формуле 0.1 * Кр1 + 0.35 * Др1 + 0.2 * Кр2 + 0.35 * Др2, округление арифметическое. Виды аналитиков data scientists Датасаентисты - общее определение нескольких профессий. Основной набор навыков – математика, программирование и знание бизнес-задач. Сочетание этих навыков в разных пропорциях и характеризует разные виды датасаентистов. Аналитики должны хорошо понимать бизнес-задачи проекта и специфику бизнеса, к тому же сейчас профессия аналитика предполагает хорошее знание статистики и хотя бы начальные навыки программирования. web-аналитика Задачи: сбор и анализ данных о посетителях веб-сайтов и их поведении на сайте Инструменты: Google Analytics, Яндекс.Метрика, Google Tag Manager маркетинговая аналитика Задачи: оценка эффективности маркетинга (UA, привлечение пользователей) Инструменты: Amplitude, Appsflyer, Facebook etc Есть маркетинговая аналитика, которая касается исследований рынка и так далее. Там совершенно иные требования к навыкам и задачи. Продуктовая аналитика что такое продукт Все, что может быть предложено на рынке с целью удовлетворения чьих-либо желаний и потребностей. В IT под продуктом обычно понимают приложение или какой-то функционал приложения. Соответственно, продуктовая аналитика — анализ того, как пользователи взаимодействуют с приложением и предложенным функционалом (и как за него платят). Близко к web-аналитике, но отличается более детальными данными про пользователя и его поведение, а не просто статистику страниц и переходов. CX/UX-исследователи Тоже близки к продуктовым аналитикам, но больше ориентированы на опыт пользователя и то, как он взаимодействует с приложением (интерфейс) и как использует приложение для решения своих задач. Основные методы – интервью, опросы, фокус-группы, UX-тесты и т.д. структура команды разработки Продуктовые аналитики тесно взаимодействуют с командами разработки (особенно если это мобильные приложения), в основном с продюсерами и разработчиками (особенно на этапе построения систем аналитики новых продуктов), с отделом маркетинга, существенно реже - с коммьюнити-менеджерами. продакт-менеджер / продюсер проджект-менеджер (PM) разработчики (клиент/сервер) дизайнеры (арт), UI аналитики тестировщики системные администраторы коммьюнити саппорт роли продуктовых аналитиков калькулятор интерфейс к базе данных специалист по дашбордам аналитик фич и апдейтов генератор идей / мастер на все руки Стадии развития продукта этапы жизни технические этапы Концепт Прототип Продукт, готовый к запуску Soft launch Global launch Оперирование Поддержка Чаще всего, конечно, продуктовые аналитики работают с продуктом в стадии оперирования - когда идет эволюционное развитие, постоянный приток новых пользователей и есть активная команда разработки. Основные задачи: анализ фич (функционала), контроль баланса, улучшение UX, поддержка продактов при проектировании новых фич. Также аналитики работают с продуктом, готовым к первому запуску и на этапах soft/global launch. Это периоды построения системы аналитики и тестирование, как пользователи реагируют в целом на продукт и на ключевой функционал продукта. Бизнес-модели компоненты все, что связано с разработкой и производством продукта все, что связано с продажей продукта, от поиска нужных клиентов до распространения продукта все, что связано с тем, как клиент будет платить и как компания будет зарабатывать варианты Subscription Model. Монетизация через подписку. Я.МУзыка, онлайн-кинотеатры и т. д. Freemium Model. Многие мобильные игры, все продукты с разными тарифными планами. Advertising Model. Продукты, которые получают деньги за счет показа рекламы. Социальные сети, Youtube и т. д. E-commerce/Marketplace Model. Магазины, маркетплейсы и классифайды. Transaction/Commission Model. Монетизация за счет комиссии. AirBnB, платежные системы типа Мир, Visa. On-Demand Model. Товар по требованию. Печать книг (Ridero), различный мерч. Licensing Model. Продажа лицензий. Microsoft Office. Pay-Per-Use Model. Плати и используй. Самокаты, облачные сервисы AWS. Crowdsourcing/Funding Model. Живут за счет донатов и пожертвований. Wikipedia. … тысячи их Полезные материалы рассказ Алексея Натекина про виды датасаентистов рассказ Валерия Бабушкина про то, почему датасаентист - очень общий термин Неплохая статья одного из аналитиков Яндекса. Его мысль про партизанской продакт-менеджмент наглядно описывает, какая роль аналитика в команде самая эффективная и, в общем-то, интересная. Хороший доклад про роли аналитиков в продуктовых (в первую очередь геймдев) командах. Немного многословно, но основные пункты освещены. фреймворк продуктовой аналитики, основанный на задачах на разных этапах развития продукта пара слов про бизнес-модели (я частично ориентировался на эти материалы): раз, два и три телеграм-канал про стартапы, любопытно посмотреть, какие вообще бывают идеи стартапов и на удовлетворение каких потребностей они ориентированы Домашнее задание Промежуточные задания необязательны и нужны для тех, кто хочет развивать свои навыки в области аналитики или в R/Python/SQL. О занятиях, которые будут оцениваться, я сообщу отдельно и не один раз. Обязательно! Настройте для себя привычную вам рабочую среду для работы с данными (R или Python). Если у вас возникнут какие-то затруднения с этим, напишите мне. В подчате #welcome напишите несколько слов о себе: какой опыт работы с R/Python/SQL и вообще языками программирования, есть ли опыт работы аналитиком (и где, если есть). Какие ожидания от курса, какие темы вам интереснее всего. подумайте и напишите мне, каких специалистов и из каких компаний вы хотели бы послушать (кого стоит попробовать пригласить). Не какие-то конкретные люди, а роли. посмотрите на ваши установленные приложения и подумайте, какие ваши потребности они реализуют попробуйте определить, как организован поток денег от вас к компании в ваших приложениях, за что вы платите и как (какая бизнес-модель используется в этом приложении) попробуйте определить самое интересное для себя приложение с точки зрения потребностей и их монетизации, чем оно вам оказалось интересным? Если это возможно, напишите, пожалуйста, свои размышления о приложениях в подчате #discussion нашего телеграм-канала. Если есть желание развиваться в сфере аналитики и продуктовой аналитики: напишите мне о своем желании в личку и скажите, какие навыки лично вы хотели бы подтянуть во время курса. поищите различные вакансии веб-аналитиков, продуктовых и маркетинговых аналитиков. Посмотрите требуемые основные навыки: что из этого вы уже умеете, чему хотели бы научиться, а чем даже понятия не имеете. Определите зону или траекторию своего развития. Если считаете, что я могу помочь вам с этим – напишите, попробуем. "],["метрики-вовлечения-pt1.html", "Метрики вовлечения pt1 Запись занятия AARRR фреймворк User Aquisition Активность и вовлечение Полезные материалы Домашнее задание", " Метрики вовлечения pt1 Запись занятия AARRR фреймворк User Aquisition Метрики привлечения пользователей в основном используются маркетинговыми аналитиками и специалистами по user aquisition, привлечению пользователей. Продуктовые аналитики в основном работают с метриками стоимости пользователя: CPA (cost per action), CPI (cost per install), хотя иметь представления о прочих метриках тоже надо. Процесс привлечения пользователей рекламодатель (тот, кто хочет привлечь пользователей) аукцион рекламной площадки (рекламная площадка выбирает, кому, когда и по какой цене показыть рекламные материалы) целевые действия (установка, платеж и т.д.) (в зависимости от того, на выполнение какого целевого действия оптимизируется рекламная сеть, в приложение будут приходить разные пользователи - те, кто вероятнее всего установит приложение/сделает платеж / сделает другое целевое действие) управление кампанией - таргетинг, бюджет, креативы (рычагов управления рекламными кампаниями не так уж и много - на кого ориентируем рекламу, какой бюджет в день рекламная сетка может потратить на привлечение пользователей, какие рекламные атериалы показываем) Маркетинговая воронка в мобильных приложениях Когда пользователи видят рекламу, они проваливаются в “воронку” — последовательность шагов, которые приводят пользователя в приложение. Вообще воронки — полезный инструмент для оценки, где и на каком этапе отваливается пользователь. реклама (баннер, playable, прочий креатив): CPM (cost per mille - сколько платим за каждые 1000 показов рекламных материалов), CPC (cost per click - сколько платим рекламной сетке за каждый клик по баннеру), СTR(click through rate – клики / показы) переход в стор установка приложения (CR, conversion rate, регистрации / показы) целевое действие (CPI, CPA) Для продуктовых аналитиков важнее всего стоимость пользователя (как правило, CPI или CPA), так как это позволяет сопоставить, сколько заплатил пользователь за время своей жизни в приложении и сколько потратили на его привлечение. То есть, окупился пользователь или нет. Оптимизировать окупаемость можно и с помощью понижения цены закупки, и с помощью повышения среднего чека / LTV пользователя. На последнее как раз влияют прождуктовые изменения, которые и входят в зону ответственности продуктовых аналитиков. Новый пользователь Основная цель рекламных кампаний – привлечение пользователей в приложение. Одна из базовых метрик этого процесса – количество новых пользователей. Однако есть сложности с самим определением, что такое новый пользователь. В частности, считать инсталлом новое физическое устройство. Или новый аккаунт пользователя. Или пользователя, который сделал покупку / подписку (e-comm, в частности). Например, когда пользователь на новый телефон устанавливает приложение и туда происходит логин с помощью его гугл/эппл аккаунта. В этом смысле устройство новое (а маркетинг закупает девайсы), а пользователь старый. Или когда пользователь пользовался приложением на телефоне. Потом удалил и через пару лет увидел рекламу и поставил заново и создал новый аккаунт. Или просто отдал телефон кому-то. Девайс старый, а пользователь новый. Другая история с новыми пользователями – это механизмы ретаргетинга. Это когда мы стараемся вернуть в приложение пользователей, которые уже были нашими пользователями, но потом отвалились. Например, мы выбираем набор девайсов с каким-то суммарным платежом более X единиц, и просим рекламной сетке именно этим устройствам показать нашу рекламу, с помощью которой мы надеемся вернуть пользователей. Этих пользователей сложно считать новыми, но рекламная кампания на них была и, соответственно, сколько-то мы потратили на возвращение этих пользователей. Активность и вовлечение Другая группа метрик - метрики активности и вовлечения пользователей в продукт. К этим метрикам относят обычно количество заходов пользователя в день (количество сессий), количество уникальных пользователей, заходящих в день в приложение. В некоторых случаях считают более длинные метрики - количество уникальных пользователей, зашедших в приложение в последнюю неделю/месяц. DAU, WAU, MAU Daily Active Users Weekly Active Users Monthly Active Users Основная метрика - DAU, как наиболее гибкая и быстро реагирующая на изменения в продукте. Месячные и недельные метрики считаются в скользящем окне, за последние 30 и 7 дней для каждой даты соответственно. Stickness / Sticky factor Иногда смотрят отношение DAU/MAU и интерпретируют как метрику залипания пользователя в проект, его лояльности. В целом это метрика вполне хорошо заменяется метриками удержания (retention). Retention rate Метрика удержания пользователя (retention) — какая доля пользователей вернулась в приложение. Во многом формула расчета ретеншена зависит от того, что мы считаем точкой отсчета. Когда речь идет о мобильных приложениях развлекательного плана (игры, стриминговые сервисы и проч.), то точкой отсчета обычно считают день инсталла, когда пользователь установил приложения. В некоторых продуктах может быть иначе, например, в e-commerce или в сервисах, предлагающих определенные услуги оффлайн (доставка продуктов), считаются только возвраты тех пользователей, которые сделали уже платеж (возвратом считается последующий платеж). В целом, метрика удержания одна из важнейших в аналитике - она позволяет понимать, насколько пользователям интересно приложение (сервис), останутся ли они в нем. Соответственно, это прямо влияет на монетизацию: когда пользователи остаются, они либо больше платят, либо, как минимум, есть шансы их побудить сделать платеж (скидками, новыми фичами и т.д.) Нюансы: install day = day 0: традиционно день инсталла считается нулевым днем. day 1/7/14/28: полезно иметь в виду, что бывают циклы, например, ретеншен в течение недели может варьировать в определенном диапазоне. Соответственно, сравнивать два периода/объекта/тестовых группы хорошо бы по одному и тому же по структуре интервалу. проблема интервала (сутки vs календарная дата): обычно считается ретеншен по календарным дням, то есть, если произошла смена даты, то это уже другой день, даже если пользователь установил приложение в 23.55. Временами встречаются вычисления ретеншена строго по 24 часовым интервалам (вернувшийся в игру через 24 часа). Метрики удержания по этим двум формулам вычисления различаются, всегда надо уточнять, как именно велся расчет. rolling retention: иногда нет возможности логировать каждый заход пользователя в приложение, поэтому используется только дата последнего захода пользователя в приложение - то есть, считается, какая доля пользователей заходила после N дня от инсталла. Иногда retention 1 дня / удержание 1 дня сокращают до ret1 / ret1d, r1 (номер дня может быть любым, не только 1). однородность когорт: когда мы считаем удержание по когорте пользователей (например, пришедшим в сентябре), то мы должны считать ретеншен только того дня, который могли прожить все пользователи. То есть, на момент 3 сентября нельзя считать ретеншен 7 дня для тех, кто пришел в приложение 31 августа - они принципиально не могли прожить 7 дней, максимум - 2 (день инсталла и 1-2 октября, 3 сентября также нельзя считать, так как день еще не закончился). Соответственно, по всей месячной когорте можно считать только ret2, даже для тех, кто пришел в начале сентября и мог провести в приложении больше дней. Иногда это минимальное количество дней, которые могли прожить пользователи всех когорт, называют окном лайфтайма. Churn rate Отвалы (churn, отток) - ситуация, когда пользователь окончательно уходит из приложения. Как правило, это достаточно определить, что пользователь больше не вернется, поэтому операционализируют в духе “отвалившийся пользователь - пользователь, который был неактивен последние N дней”. Также как и ретеншен, операционализация отвала может зависеть от приложения и сервиса. Стоить помнить, что отток не тождественен удержанию с другим знаком, хотя достаточно близок по смыслу. Sessions per day Еще одна метрика вовлеченности пользователя в продукт - сколько раз пользователь открывает приложение в течение дня. В более общем виде - какие-то значимые активные действия в единицу времени. Количество сессий в день можно интерпретировать как степень рутинизированности, включенности в повседневные практики пользователя. Для разных продуктов и сервисов, само собой, будут свои критерии - для игр жанра match3 нормально, если пользователь 4-6 раз в день открывает приложение. А вот для приложения оплаты штрафов или банковских приложений это была бы странная метрика, там вообще могут потребоваться другие способы измерения и вовлечения. Полезные материалы Статья про Rolling retention и Retention rate от Олега Якубенкова. Статья от dev2dev про Retention. Список фреймфорков, которые используют продуктовые менеджеры в своей работе. Оффтоп: cмешной случай, как потеряли информацию о 16 тысячах заболевших граждан. Хороший пример, почему для работы с большими данными (да и просто с данными) Excel не очень полезен. Домашнее задание Домашние занятия для желающих. Если будут вопросы, пишите в канал #discussion. Если возникнет необходимость получить от меня какие-то персональные комментарии - пишите в личку. Задание можете выполнять на любом доступном вам языке / среде для статистики. level 1 (IATYTD) Обновите знания по работе с табличками — аггрегации (групировки), слияния, создание и модификация колонок. Ссылка на конспекты прошлого курса: https://mar231s.upravitelev.info/ level 2 (HNTR) Необходимо подсчитать и нарисовать, сколько пользователей в день приходит в приложение, в том числе и с разбивкой по платформам. Датасет: https://gitlab.com/hse_mar/mar211f/-/raw/main/data/installs.csv level 3 (HMP) Используя датасет по заходам пользователей в приложение (dau.csv), подсчитайте и отобразите на графике, сколько пользователей в день заходит в приложение (DAU). Ссылка на файл. Осторожно, файл около 400мб. level 4 (UV) На основе данных по логинам нарисуйте area plot DAU проекта, в котором цветами выделите группы пользователей по количеству дней с момента инсталла: группа 1: 0 дней с инсталла группа 2: 1-7 дней с момента инсталла группа 3: 8-28 дней с инсталла группа 4: более 28 дней с инсталла У вас должно получится что-то вроде слоеного пирога, где цветами выделены группы. Подумайте, есть ли необходимость рисовать этот график не в абсолютных числах (количество пользователей), а в долях каждой группы от DAU, в чем могут быть плюсы и минусы такого графика. Возможно, вам потребуется нарисовать графики разных типов, чтобы ответить на этот вопрос. Попробуйте подумать, что говорит подобный график о продукте и его пользователях. Есть ли у него проблемные зоны, над которыми надо поработать или которые могут влиять на стратегию развития и/или оперирования продукта? level 5 (N) Постройте графики DAU, MAU и их отношения для данных за июль. Проинтерпретируйте метрику DAU/MAU, что она говорит о проекте? "],["метрики-вовлечения-pt2.html", "Метрики вовлечения pt2 Запись занятия Код занятия на Python Разбор домашнего задания Расчет retention Домашнее задание", " Метрики вовлечения pt2 Запись занятия Код занятия на Python https://colab.research.google.com/drive/1FcFTz7sI8QXhVLcLnshyHFMdGS5znlw5?usp=sharing Разбор домашнего задания level 2 (HNTR) Необходимо подсчитать и нарисовать, сколько пользователей в день приходит в приложение, в том числе и с разбивкой по платформам. Датасет: https://gitlab.com/hse_mar/mar211f/-/raw/main/data/installs.csv Решение: # подключаем пакеты (они до этого должны быть установлены) library(data.table) library(plotly) # если есть ошибка с %&gt;%, то явно подключаем соответствующий пакет library(magrittr) # импортируем данные installs &lt;- fread(&#39;https://gitlab.com/hse_mar/mar211f/-/raw/main/data/installs.csv&#39;) # считаем количество уникальных пользователей по дням intalls_stat &lt;- installs[, list(n_users = uniqueN(user_pseudo_id)), by = list(dt, media_source)] # сортируем по дате инсталла intalls_stat &lt;- intalls_stat[order(dt)] # рисуем график plot_ly(intalls_stat, x = ~dt, y = ~n_users, color = ~media_source, type = &#39;scatter&#39;, mode = &#39;none&#39;, stackgroup = &#39;one&#39;) %&gt;% layout( title = &#39;Установки приложения по дням&#39;, xaxis = list(title = &#39;&#39;), yaxis = list(title = &#39;&#39;, rangemode = &#39;tozero&#39;)) %&gt;% config(displayModeBar = FALSE) level 4 (UV) На основе данных по логинам нарисуйте area plot DAU проекта, в котором цветами выделите группы пользователей по количеству дней с момента инсталла: группа 1: 0 дней с инсталла группа 2: 1-7 дней с момента инсталла группа 3: 8-28 дней с инсталла группа 4: более 28 дней с инсталла У вас должно получится что-то вроде слоеного пирога, где цветами выделены группы. Подумайте, есть ли необходимость рисовать этот график не в абсолютных числах (количество пользователей), а в долях каждой группы от DAU, в чем могут быть плюсы и минусы такого графика. Возможно, вам потребуется нарисовать графики разных типов, чтобы ответить на этот вопрос. Попробуйте подумать, что говорит подобный график о продукте и его пользователях. Есть ли у него проблемные зоны, над которыми надо поработать или которые могут влиять на стратегию развития и/или оперирования продукта? Решение: # если падает по таймауту options(timeout=360) # импортируем датасает dau &lt;- fread(&#39;https://gitlab.com/hse_mar/mar211f/-/raw/main/data/dau.csv&#39;) # считаем количество дней от инсталла dau[, lifetime := login_dt - install_dt] # делим на группы dau[, lifetime_group := cut(lifetime, breaks = c(-Inf, -1, 0, 7, 28, Inf), ordered_result = TRUE)] # если хотим перезадать порядок уровней # dau[, lifetime_group_ := factor(lifetime_group, # levels = c(&#39;(-1,0]&#39;, # &#39;(28, Inf]&#39;, &#39;(0,7]&#39;, # &#39;(7,28]&#39;, &#39;(-Inf,-1]&#39;))] # второй способ разметить группы # dau[lifetime == 0, lifetime_group_3 := &#39;0. 0 day&#39;] # dau[lifetime &gt;= 1 &amp; lifetime &lt;= 7, lifetime_group_3 := &#39;1. 1-7 days&#39;] # dau[lifetime &gt;= 8 &amp; lifetime &lt;= 28, lifetime_group_3 := &#39;2. 8-28 days&#39;] # dau[lifetime &gt;= 28 &amp; lifetime &lt;= 90, lifetime_group_3 := &#39;3. 28+ days&#39;] # создаем отдельную группу для тех, про кого мы не знаем # dau[is.na(lifetime_group), lifetime_group_3 := &#39;unknown&#39;] # третий метод, с помощью fcase # dau[, lifetime_group := fcase( # lifetime == 0, &#39;0 дней&#39;, # lifetime &gt;= 1 &amp; lifetime &lt;= 7, &#39;1-7 дней&#39; # )] # считаем DAU dau_stat &lt;- dau[, list(n_users = uniqueN(user_pseudo_id)), keyby = list(login_dt, lifetime_group)] dau_stat[, total_users := sum(n_users), by = login_dt] dau_stat[, share := n_users / total_users] # area-plot plot_ly(dau_stat, x = ~login_dt, y = ~n_users, color = ~lifetime_group, type = &#39;scatter&#39;, mode = &#39;none&#39;, stackgroup = &#39;one&#39;) %&gt;% layout( title = &#39;DAU по группам пользователей&#39;, xaxis = list(title = &#39;&#39;), yaxis = list(title = &#39;&#39;, rangemode = &#39;tozero&#39;)) %&gt;% config(displayModeBar = FALSE) # график линиями plot_ly(dau_stat, x = ~login_dt, y = ~n_users, color = ~lifetime_group, type = &#39;scatter&#39;, mode = &#39;lines&#39;) %&gt;% layout( title = &#39;DAU по группам пользователей&#39;, xaxis = list(title = &#39;&#39;), yaxis = list(title = &#39;&#39;, rangemode = &#39;tozero&#39;)) %&gt;% config(displayModeBar = FALSE) level 5 (N) Постройте графики DAU, MAU и их отношения для данных за июль. Проинтерпретируйте метрику DAU/MAU, что она говорит о проекте? Решение. Строим график MAU. # берем интересующие нас дни dates &lt;- dau[login_dt &gt;= &#39;2022-07-01&#39;, sort(unique(login_dt))] # проходим циклом lapply mau_stat &lt;- lapply(dates[1:2], function(x) { # берем данные в интервале &quot;наша дата - 30 дней -- наша дата&quot; result &lt;- dau[login_dt &gt;= x - 30 &amp; login_dt &lt;= x] # считаем, сколько пользователей заходило за это время (mau) result &lt;- result[, list(dt = x, dt_lb = x - 30, mau = uniqueN(user_pseudo_id))] result }) # собираем все в табличку mau_stat &lt;- rbindlist(mau_stat) # аналогичное решение, более современное по функциям # + считаем одновременно dau и mau library(purrr) mau_stat &lt;- map_df(dates, function(x) { result &lt;- dau[, list( dt = x, dt_lb = x - 30, metric_dau = uniqueN(user_pseudo_id[login_dt == x]), metric_mau = uniqueN(user_pseudo_id[login_dt &gt;= x - 30 &amp; login_dt &lt;= x]) )] result }) setDT(mau_stat) # считаем stickiness mau_stat[, stickiness := metric_dau / metric_mau] # рисуем DAU и MAU plot_ly(mau_stat, x = ~dt, y = ~metric_mau, type = &#39;scatter&#39;, mode = &#39;lines&#39;, name = &#39;MAU&#39;) %&gt;% add_trace(y = ~metric_dau, name = &#39;DAU&#39;) %&gt;% layout( title = &#39;DAU и MAU&#39;, yaxis = list(rangemode = &#39;tozero&#39;) ) %&gt;% config(displayModeBar = FALSE) # рисуем stickiness plot_ly(mau_stat, x = ~dt, y = ~stickiness, type = &#39;scatter&#39;, mode = &#39;lines&#39;) %&gt;% layout( title = &#39;DAU / MAU&#39;, yaxis = list(rangemode = &#39;tozero&#39;) ) %&gt;% config(displayModeBar = FALSE) Расчет retention Общая логика расчета: - считаем lifetime - считаем количество пользователей на каждый день от инсталла - считаем долю этих пользователей от всего пользователей когорты - ограничиваем на общий доступный лайфтайм - рисуем график - опционально – добавляем группировку # берем только тех, кто пришел в июне retention &lt;- dau[install_dt &gt;= &#39;2022-06-01&#39;] retention &lt;- retention[install_dt &lt; &#39;2022-07-01&#39;] # ограничиваем на минимальное общее количество дней retention &lt;- retention[lifetime &lt;= 30 &amp; lifetime &gt;= 0] # считаем количество вернувшихся retention_stat &lt;- retention[, list(returned = uniqueN(user_pseudo_id)), keyby = list(platform, lifetime)] # считаем,с колько всего было retention_stat[, total_users := returned[lifetime == 0], by = platform] # второй вариант расчета total_users, через merge retention_stat &lt;- merge( retention_stat, retention_stat[lifetime == 0, list(platform, total_users_2 = returned)], by = &#39;platform&#39;, all.x = TRUE ) # считаем retention retention_stat[, ret := returned / total_users] # рисуем график plot_ly(retention_stat, x = ~lifetime, y = ~ret, color = ~platform, type = &#39;scatter&#39;, mode = &#39;lines&#39;) %&gt;% layout( title = &#39;Retention rate&#39;, yaxis = list(rangemode = &#39;tozero&#39;) ) %&gt;% config(displayModeBar = FALSE) Домашнее задание level 1 (IATYTD) Внимательно разберите решения заданий (материалы конспекта). level 2 (HNTR) Постройте график ретеншена для когорты пользователей, пришедшей в июне, с разбивкой по источникам привлечения (media_source). Для этого вам потребуются следующие датасеты: Инсталлы: https://gitlab.com/hse_mar/mar211f/-/raw/main/data/installs.csv Логины: https://gitlab.com/hse_mar/mar211f/-/raw/main/data/dau.csv level 3 (HMP) Постройте линейный график retention 1 day (ret1) для всех дневных когорт. Т.е. по оси OX должна быть дата инсталла, по оси OY – значение ретеншена первого для пользователей, пришедших в этот день. level 4 (UV) Добавьте на этот график группировку по источникам трафика (media_source). level 5 (N) Постройте и сравните графики rolling retention и retention rate (возьмите данные за логины и инсталлы из практикума). Для rolling retention необходимо: посчитать максимальный лайфтайм пользователя посчитать количество пользователей по лайфтайму cделать обратную кумулятивную сумму cумму поделить на количество установок (для lifetime == 0 значения количества инсталлов и обратная кумсумма должны совпадать) "],["метрики-монетизации-pt1.html", "Метрики монетизации pt1 Запись занятия Код занятия на Python Разбор домашнего задания Метрики монетизации Домашнее задание", " Метрики монетизации pt1 Запись занятия Код занятия на Python https://colab.research.google.com/drive/1gdtpFd3LjzRSsFwPrKP-OARjDXDU3F1v?usp=sharing Разбор домашнего задания level 2 (HNTR) Постройте график ретеншена для когорты пользователей, пришедшей в июне, с разбивкой по источникам привлечения (media_source). Для этого вам потребуются следующие датасеты: Инсталлы: https://gitlab.com/hse_mar/mar211f/-/raw/main/data/installs.csv Логины: https://gitlab.com/hse_mar/mar211f/-/raw/main/data/dau.csv library(data.table) library(plotly) ## Loading required package: ggplot2 ## ## Attaching package: &#39;plotly&#39; ## The following object is masked from &#39;package:ggplot2&#39;: ## ## last_plot ## The following object is masked from &#39;package:stats&#39;: ## ## filter ## The following object is masked from &#39;package:graphics&#39;: ## ## layout # чтобы загрузка не обрывалась по таймауту, если слабый интернет options(timeout=360) installs &lt;- fread(&#39;https://gitlab.com/hse_mar/mar211f/-/raw/main/data/installs.csv&#39;) logins &lt;- fread(&#39;https://gitlab.com/hse_mar/mar211f/-/raw/main/data/dau.csv&#39;) # выделяем инсталлы в июне installs_june &lt;- installs[dt &gt;= &#39;2022-06-01&#39; &amp; dt &lt; &#39;2022-07-01&#39;] # считаем количество пользователей по платформам installs_june[, uniqueN(user_pseudo_id), keyby = media_source] ## Key: &lt;media_source&gt; ## media_source V1 ## &lt;char&gt; &lt;int&gt; ## 1: &lt;NA&gt; 36169 ## 2: Facebook Ads 1297 ## 3: applovin_int 36714 ## 4: googleadwords_int 7767 ## 5: organic 32 ## 6: other 6869 ## 7: unityads_int 21932 # при необходимости укрупняем installs_june[media_source %in% c(&#39;organic&#39;, &#39;other&#39;) | is.na(media_source), media_source := &#39;organic&#39;] # смотрим, нет ли тех, кто два раза устанавливал приложение installs_june[, list(n_install_dates = length(dt)), user_pseudo_id][n_install_dates &gt; 1] ## user_pseudo_id n_install_dates ## &lt;char&gt; &lt;int&gt; ## 1: 000ee53a25d9b57b29a8513070325bba 2 ## 2: 0114C14103154E4B8202B09684ECBC1F 2 ## 3: 01958D392F90428AA0DAF9D94CC699DE 2 ## 4: 09B886173CAF46E7B99C2927CE954E9B 2 ## 5: 0DA2A73360594B5D94C77489A563C9C9 2 ## 6: 1A041DCE27EC4DE984379C91778615E1 2 ## 7: 1CB08A3B991A41848CF193759534A8E3 2 ## 8: 1FC5CCB7EAA34A1CA4D4FB9731AAD6B4 2 ## 9: 2488537605DD48DC89CB9AE2A7F056DC 2 ## 10: 2585F39E330445CCB04D86C8874E04AE 2 ## 11: 2E7FE3A85A434C19AE66C5F5A9909488 3 ## 12: 30B149EB924045D7B710BB0ECCD3E3C8 2 ## 13: 330704BC3B27431B910C5EFF17F7E224 2 ## 14: 34cd9bf8909ccd8ff7845e57374284d1 2 ## 15: 369FD7EBC865452CB1B33E5E98AC447C 2 ## 16: 36D082CC8AB7447683877B1AFED0EDDB 2 ## 17: 382548ABD43A4CC3956408AA15065DD5 2 ## 18: 3B22021A23624273B976BB68F7BC133E 2 ## 19: 3B41BA33DDCA463180F1288B1FDAB9E5 2 ## 20: 3CFDCBE58131436483C5DB672E0C8BA5 2 ## 21: 3E5DBDEB38FE408FA281C75B5B33D08A 2 ## 22: 41E59CD840224F4286041CF23454D1A5 2 ## 23: 42F53713F7B04EF8ADA81A51EDFAA0FC 2 ## 24: 453D178E341A45409852BFBEF7668FCA 2 ## 25: 4df8d48b980fb52e7143b8f4f6a86eec 2 ## 26: 53d5883b315f11beb96e759eeb6c6946 2 ## 27: 541291B4FC0A472C8A18F33FCBB578E7 2 ## 28: 55734100B47F414CBB3575028EC0E887 2 ## 29: 58E14628B03046219960479EA035BAC4 2 ## 30: 5f86721f15e1fe055162a1251f2f8b01 2 ## 31: 67A5140641B44E26B9F9699A767EAA1B 2 ## 32: 696f7a53d58e73d2a1b9c5ff841741d6 2 ## 33: 6F22E223CB3D4DEF9CE5F64073099A8C 3 ## 34: 7044781DFEC247C79D9641EFB09CDF79 2 ## 35: 78264f9fd5ab87d279dc8f7c98279f55 2 ## 36: 79f6234ccd8fc0ccfcd4058a9d4173f6 2 ## 37: 7F25AD2C389542048506DF670BD714BD 2 ## 38: 8159da026a6e5393b11783bb56df4c14 2 ## 39: 822abdbc7bef93fbe985f4e89651dd75 2 ## 40: 83F7F0494B2F4D49B934C12A92B4B299 2 ## 41: 84e435c0c8689635cf96ceeabf52c534 2 ## 42: 854366FB9D794A83B85B666A808DF8C2 2 ## 43: 8C03EE3FBBFC472BB26DB331567DAA6A 2 ## 44: 8FD70E7743B74FDA8B398B8E59B6D393 2 ## 45: 908C0586AFD14790A2FEAD8380D5E5AC 2 ## 46: 9655A5286F2D4782BB95B97C4443AB19 2 ## 47: 98AAE0DB60B44B649FB45DAFF50E5756 2 ## 48: 9B1CAF9AB0B2438A92D7FB377BDF1CD5 2 ## 49: 9DC9EC1BE76D48AD9161A8FDA1AD8F5D 2 ## 50: 9EBF8F8182D84FBD99DE634AC3467F7E 2 ## 51: A1084F73187648EFAAD54B3FC01A25EF 2 ## 52: A3DD0C1CACA4442085DBFFC493DBEFDE 2 ## 53: A7072DB51E414373B45AF4495BE5E30D 2 ## 54: ABD07667D3124C969E098EED5FFD25B2 2 ## 55: AE7CF2B145C94D94A2782A4986A56C7A 2 ## 56: BA8BE90B36464ED48B1F6596C8B9218A 2 ## 57: BCF666CE7D004703B1C7A998E0029B3D 2 ## 58: BD2FC2B3E09441AAA0C8DAAF079DFEE7 2 ## 59: BEE44FD3EB6B464FB19E89B3DD18C1D8 2 ## 60: CB97620A41514DD6A572406AC15DA962 3 ## 61: CEB5B07C3DE244B4B042D7663C4957F2 2 ## 62: D367DC87B0AF47CEB44219CB5C16B136 2 ## 63: D8DD91C418E644E6BD3A2A46DE12DD86 3 ## 64: DF4612D16A6C49A08C1C7F64B43ADCF0 2 ## 65: E5E18D1017294B0992C09A454C9519A8 2 ## 66: ECDC46825D71492794912D761A78A71F 2 ## 67: EF4084E36ABA4A889CC21272B1791355 2 ## 68: F2FB00FFF2C74EA4B8BC87992CED3B6A 2 ## 69: F559AD32A74E411C9B60873CCC3614A1 2 ## 70: F73BD84C3713442187AF3289DA2D2172 2 ## 71: FEE12ECCA2E94760909C8F64EFEF066B 2 ## 72: FFFD930C3F9F4AB7B9786983044292FE 2 ## 73: a43d9e6b9741ccb23d0138d3d7ba325a 2 ## 74: a92b088adfb0f9374dcfec4f884c76d9 2 ## 75: add417438334536d4e41fee42cecbeac 2 ## 76: b35107c77a6c0a3e5e55dc980c0c435c 2 ## 77: b8b9848ce34f9661eae6b471522d5265 2 ## 78: b929015e9c4eeee3e1d4a7e6a22b39d2 2 ## 79: cf38d8f4f997cc7a2bde1cf6b9636a51 2 ## 80: d101bd547e90e2a43ffbe29cdc0d7c6a 2 ## 81: de47c1adf204ee72a6745901052a26ae 2 ## 82: df7e04c01ef23152ce370e6655de6133 2 ## 83: ee01a31f793d9200e110ba607747d2d2 2 ## 84: f0d4270e629a31d5f73ba47d6fb8de07 2 ## 85: f2cd8d5642834168fa5dcfeb42a4b5d6 2 ## 86: f43c58ff000c5ba637bb622848c2597b 2 ## 87: fa6827f8ebd2805fe69ac2fcdafbe18a 2 ## 88: fd72559f6d926b4e770290d48fb422e5 2 ## user_pseudo_id n_install_dates users_reinstalls &lt;- installs_june[, list(n_install_dates = length(dt)), user_pseudo_id][n_install_dates &gt; 1, unique(user_pseudo_id)] # чистим таких пользователей # installs_june &lt;- installs_june[!user_pseudo_id %in% users_reinstalls] # можно удалить, можно взять первый инсталл # installs_june &lt;- installs_june[order(user_pseudo_id, dt)] # installs_june &lt;- installs_june[, .SD[1], by = user_pseudo_id] # присоединяем к установкам логины installs_june &lt;- merge( installs_june, logins, by = c(&#39;user_pseudo_id&#39;, &#39;platform&#39;), all.x = TRUE ) # вычисляем лайфтайм installs_june[, lifetime := login_dt - dt] # ищем пользователей, у которых логин был раньше даты инсталла installs_june[login_dt &lt; dt, uniqueN(user_pseudo_id)] ## [1] 204 # чистим таких пользователей installs_june &lt;- installs_june[!user_pseudo_id %in% installs_june[login_dt &lt; dt, unique(user_pseudo_id)]] # еще одна чистка, для красоты -- берем только тех пользователей, у которых есть lifetime = 0 installs_june &lt;- installs_june[user_pseudo_id %in% installs_june[lifetime == 0, unique(user_pseudo_id)]] # считаем количество вернувшихся на кайждый день лайфтайма installs_june_stat &lt;- installs_june[, list(returned = uniqueN(user_pseudo_id)), by = list(media_source, lifetime)] # так как выше почистили путешественников во времени, эта фильтрация избыточна installs_june_stat &lt;- installs_june_stat[lifetime &gt;= 0] # считаем количество инсталлов, data.table-way installs_june_stat[, total_users := returned[lifetime == 0], by = media_source] # # тоже количество инсталлов, староверы/python-way # installs_june_stat &lt;- merge( # installs_june_stat, # installs_june_stat[lifetime == 0, list(media_source, total_users = returned)], # by = &#39;media_source&#39;, all.x = TRUE # ) # считаем собственно ретеншен installs_june_stat[, ret := returned / total_users] # сортируем для красоты installs_june_stat &lt;- installs_june_stat[order(lifetime)] # рисуем график, попутно накладываем ограничение на количество дней лайтайма plot_ly(installs_june_stat[lifetime &lt;= 30], x = ~lifetime, y = ~ret, color = ~media_source, type = &#39;scatter&#39;, mode = &#39;lines&#39;) %&gt;% layout( title = &#39;Ретеншен июньской когорты в зависимости от источников трафика&#39;, yaxis = list(rangemode = &#39;tozero&#39;) ) %&gt;% config(displayModeBar = FALSE) level 3 (HMP) Постройте линейный график retention 1 day (ret1) для всех дневных когорт. Т.е. по оси OX должна быть дата инсталла, по оси OY – значение ретеншена первого для пользователей, пришедших в этот день. daily_ret &lt;- merge( installs, logins, by = c(&#39;user_pseudo_id&#39;, &#39;platform&#39;), all.x = TRUE ) # считаем лайфтайм daily_ret[, lifetime := login_dt - dt] # ищем пользователей, у которых логин был раньше даты инсталла daily_ret[login_dt &lt; dt, uniqueN(user_pseudo_id)] ## [1] 444 # чистим таких пользователей daily_ret &lt;- daily_ret[!user_pseudo_id %in% daily_ret[login_dt &lt; dt, unique(user_pseudo_id)]] # еще одна чистка, для красоты -- берем только тех пользователей, у которых есть lifetime = 0 daily_ret &lt;- daily_ret[user_pseudo_id %in% daily_ret[lifetime == 0, unique(user_pseudo_id)]] # считаем, сколько вернулось в каждой дневной когорте по дням от инсталла daily_ret_stat &lt;- daily_ret[, list(returned = uniqueN(user_pseudo_id)), by = list(dt, login_dt, lifetime)] # из-за нашей чистки странных пользователей у нас пропали некоторые даты с lifetime = 0 # для красоты их можно восстановить, но необязательно # считаем количество всего пользователей в когорте # daily_ret_stat[, total_users := returned[lifetime == 0], by = dt] daily_ret_stat &lt;- merge( daily_ret_stat[lifetime == 0, list(dt, total_users = returned)], daily_ret_stat, by = &#39;dt&#39;, all.x = TRUE ) # считаем ретеншен daily_ret_stat[, ret := returned / total_users] # сортируем daily_ret_stat &lt;- daily_ret_stat[order(dt, lifetime)] # daily_ret_stat &lt;- daily_ret_stat[!dt %in% c(&#39;2022-06-25&#39;, &#39;2022-07-06&#39;, &#39;2022-07-20&#39;)] # рисуем простой график # plot_ly(daily_ret_stat[lifetime == 1], # x = ~dt, y = ~ret, # type = &#39;scatter&#39;, mode = &#39;lines&#39;) %&gt;% # layout( # yaxis=list(rangemode = &#39;tozero&#39;) # ) # чтобы сортирвока линий была нормальная ret_days &lt;- c(1, 3, 7, 14, 30) daily_ret_stat_plot &lt;- daily_ret_stat[lifetime %in% ret_days] daily_ret_stat_plot[, lifetime_cat := factor(lifetime, levels = ret_days)] # рисуем график ретеншена дневных когорт plot_ly(daily_ret_stat_plot, x = ~dt, y = ~ret, color = ~lifetime_cat, type = &#39;scatter&#39;, mode = &#39;lines&#39;) %&gt;% layout( title = &#39;Retention rate дневных когорт&#39;, yaxis = list(rangemode = &#39;tozero&#39;) ) %&gt;% config(displayModeBar = FALSE) level 5 (N) Постройте и сравните графики rolling retention и retention rate (возьмите данные за логины и инсталлы из практикума). # сначала считаем просто ret1 по всей июньской когорте, без разбивки по каналм привлечения # оставляем группировку только по дням лайфтайма retention_type &lt;- installs_june[, list(returned = uniqueN(user_pseudo_id)), by = list(lifetime)] # считаем количество инсталлов, data.table-way retention_type[, total_users := returned[lifetime == 0]] # считаем собственно ретеншен retention_type[, ret_rate := returned / total_users] Для rolling retention необходимо: посчитать максимальный лайфтайм пользователя посчитать количество пользователей по лайфтайму cделать обратную кумулятивную сумму cумму поделить на количество установок (для lifetime == 0 значения количества инсталлов и обратная кумсумма должны совпадать) # считаем rolling retention # считаем количество пользователей, в зависимости от того, на какой максимальный день от логина они вернулись rrolling &lt;- installs_june[, list(lifetime = max(lifetime)), by = list(user_pseudo_id, dt)] # считаем количество дней от инсталла до последнего логина rrolling_stat &lt;- rrolling[, list(n_users = uniqueN(user_pseudo_id)), keyby = lifetime] # нужна обратная кумулята, так как мы считаем &quot;сколько пришло после дня x&quot; # а в статистике у нас &quot;сколько пришло в день x&quot; - то есть, для каждого дня надо получить, # накопительную сумму этого и всех следующих дней. а это делается с помощью обратной кумуляты # для этого мы переворачиваем значения колонки с помощью rev(), считаем обычную кумуляту # а потом результат переворачиваем обратно # чтобы понять результат, попробуйте выражения: 1:5; rev(1:5), cumsum(1:5), cumsum(rev(1:5)), rev(cumsum(rev(1:5))) rrolling_stat[, returned_after := rev(cumsum(rev(n_users)))] # или более простой вариант rrolling_stat = rrolling_stat[order(-lifetime)] rrolling_stat[, returned_after_2 := cumsum(n_users)] rrolling_stat = rrolling_stat[order(-lifetime)] # проверяем rrolling_stat[, all.equal(returned_after, returned_after_2)] ## [1] TRUE # объединяем retention_type &lt;- merge( retention_type, rrolling_stat, by = &#39;lifetime&#39;, all.x = TRUE ) retention_type[, ret_rolling := returned_after / total_users] retention_type &lt;- retention_type[lifetime &lt;= 30] # и рисуем plot_ly(retention_type, x = ~lifetime, y = ~ret_rate, type = &#39;scatter&#39;, mode = &#39;lines&#39;, name = &#39;Retention rate&#39;) %&gt;% add_trace(y = ~ret_rolling, name = &#39;Rolling retention&#39;) %&gt;% layout( title = &#39;Retention rate vs Rolling retention, июньская когорта&#39;, yaxis = list(rangemode = &#39;tozero&#39;) ) %&gt;% config(displayModeBar = FALSE) Метрики монетизации Gross / Net Gross - общая сумма всех платежей. Обычно полезно для финансистов и прочей отчетности. Net (revenue) - сумма платежей после вычета налогов и комиссии магазина приложений. Полезно для вычисления метрик ARPU/ARPPU и их сравнения со стоимостью закупки пользователей (т. е. для оценки юнит-экономики и окупаемости проекта). Конверсия Обычно под конверсией понимают ситуацию, когда пользователь меняет один статус на другой. Например, становится из неплатящего платящим пользователем (совершает платеж). Нередко говорят “конверсия в корзину” и подобно – то есть, какая доля пользователей после просмотра товаров перешла в корзину (готова сделать платеж). Конверсия в платящих (здесь и далее мы говорим про это) считается по такой формуле: Conversion = N Paying Users / N Users Практикум Посчитать, какая доля пользователей стала платящими в интервале 7 дней о инсталла, должно получиться 1 число. Игнорируйте install_dt в табличке payments, используйте dt из installs payments &lt;- fread(&#39;https://gitlab.com/hse_mar/mar211f/-/raw/main/data/payments_custom.csv&#39;) # рисоединяем к инсталлам платежи conversion &lt;- merge( installs, payments, by = c(&#39;user_pseudo_id&#39;, &#39;platform&#39;), all.x = TRUE ) # считаем лайфтайм conversion[, lifetime := pay_dt - dt] # так как хотим считать метрику на 7 день от инсталла, то мы должны проконтролировать # что все пользователи могли прожить столько дней в приложении # поэтому оставляем инсталлы только по 2022-07-24 conversion &lt;- conversion[dt &lt;= &#39;2022-07-24&#39;] # совершенно примитивным способом считаем, сколько было пользователей, кто сделал платеж # до седьмого дня от инсталла включительно # при этом сюда не попадут пользователи, которые не делали платежей, так как сравнение lifetime &lt;= 7 # отсекает значения, когда lifetime is null (нет значений, так как не платил и нет дату платежа) conversion[lifetime &lt;= 7, uniqueN(user_pseudo_id)] / conversion[, uniqueN(user_pseudo_id)] ## [1] 0.01866886 # синтаксически другой способ расчета цифры, более data.table-way conversion[, uniqueN(user_pseudo_id[lifetime &lt;= 7]) / uniqueN(user_pseudo_id)] ## [1] 0.01867702 Домашнее задание level 1 (IATYTD) Внимательно разберите решения заданий (материалы конспекта). level 2 (HNTR) На основе данных по платежам нарисуйте area plot подневную структуру гросса проекта, в котором цветами выделите группы пользователей по количеству дней с момента инсталла: группа 1: 0 дней с инсталла группа 2: 1-7 дней с момента инсталла группа 3: 8-28 дней с инсталла группа 4: более 28 дней с инсталла Решение аналогично такому же заданию на расчет структуры DAU. level 3 (HMP) Посчитайте по каждой платформе конверсию в платящих в день инсталла. Когорта – пришедшие в июне. Делать аналогично динамике ретеншена первого дня. level 4 (UV) Постройте график накопительной конверсии для пользователей, кто пришел в июне. Для этого надо сначала посчитать, в какой день от инсталла пользователь сделал платеж (lifetime. Потом посчитать, сколько пользователей сделало первый платеж в 0-30 дни от инсталла (new payers). Посчитать накопительную сумму по количеству пользователей (cumulative new payers). Посчитать отношение cumulative new users / total users Нарисовать график. level 5 (N) Постройте график накопительной конверсии в когорте июньскийх пользователей с разбивкой по источнику пользователей. "],["c5_monetization.html", "Метрики монетизации pt.2 Запись занятия Код занятия на Python Разбор домашнего задания ARPU / ARPPU Полезные материалы Домашнее задание", " Метрики монетизации pt.2 Запись занятия Код занятия на Python https://colab.research.google.com/drive/1tAAkLUsyck3OJE-994owPh3TIGJI_qDX?usp=sharing Разбор домашнего задания level 4 (UV) Постройте график накопительной конверсии с разбивкой по источнику пользователей. library(data.table) library(plotly) # импортируем данные installs &lt;- fread(&#39;https://gitlab.com/hse_mar/mar211f/-/raw/main/data/installs.csv&#39;) payments &lt;- fread(&#39;https://gitlab.com/hse_mar/mar211f/-/raw/main/data/payments_custom.csv&#39;) # к платежам присоединяем дату инсталла и источник трафика conversion &lt;- merge( payments, installs[, list(user_pseudo_id, media_source, dt)], by = &#39;user_pseudo_id&#39;, all.x = TRUE ) # берем июньскую когорту и ограничиваем даты лайфтайма conversion[, lifetime := pay_dt - dt] conversion &lt;- conversion[dt &lt; &#39;2022-07-01&#39;] conversion &lt;- conversion[lifetime &gt;= 0 &amp; lifetime &lt;= 30] # беру минимальный день от инсталла # это будет день первого платежа conversion_stat &lt;- conversion[, list(lifetime = min(lifetime)), by = list(user_pseudo_id, media_source)] # считаю количество пользователей, которые сделали платеж на этот день conversion_stat &lt;- conversion_stat[, list(new_payers = uniqueN(user_pseudo_id)), by = list(lifetime)] # считаю, сколько всего было пользователей в когорте conversion_stat[, total_users := installs[dt &lt; &#39;2022-07-01&#39;, uniqueN(user_pseudo_id)]] # сортирую и считаю накопительное количество пользователей, которые сделали # первый платеж в этот день от инсталла conversion_stat &lt;- conversion_stat[order(lifetime)] conversion_stat[, new_payers_cum := cumsum(new_payers)] # считаю накопительную конверсию в платящих conversion_stat[, cum_conversion := new_payers_cum / total_users] # рисую plot_ly( conversion_stat, x = ~lifetime, y = ~cum_conversion, type = &#39;scatter&#39;, mode=&#39;lines&#39; ) %&gt;% layout( title = &#39;Накопительная конверсия&#39;, yaxis = list(rangemode = &#39;tozero&#39;) ) %&gt;% config(displayModeBar = FALSE) ARPU / ARPPU Averange revenue per user - сумма платежей за определенный период, деленная на общее количество пользователей когорты. Средний чек, наверное, одна из самых важных метрик для оперирования продуктом, так как изучение структуры ARPU позволяет понять, за что платят пользователи и как можно улучшить эту метрику и так далее. Average revenue per paying user - сумма платежей за определенный период, деленная на количество платящих пользователей когорты. Обе метрики считаются в определенном окне (количестве дней от инсталла) - обычно 7, 28 или 30 дней. Это необходимо для того, чтобы учесть ситуацию, когда пользователи одной когорты (месячной, например) могли прожить разное количество дней в приложении. Или когда необходимо сравнить разные каналы привлечения, рекламные кампании или группы аб-тестов. Для оценки динамики метрики и приянтия продуктовых решений (на какой день от инсталла что-то сломалось) часто рисуют кривую кумулятивного ARPU. # расчет во многом похож на накопительную конверсию, так как тоже считается накопительно # но не количество пользователей, сделавших первый платеж, а просто выручка # повторяющийся блок # к платежам присоединяем дату инсталла и источник трафика conversion &lt;- merge( payments, installs[, list(user_pseudo_id, media_source, dt)], by = &#39;user_pseudo_id&#39;, all.x = TRUE ) # берем июньскую когорту и ограничиваем даты лайфтайма conversion[, lifetime := pay_dt - dt] conversion &lt;- conversion[dt &lt; &#39;2022-07-01&#39;] conversion &lt;- conversion[lifetime &gt;= 0 &amp; lifetime &lt;= 30] # считаем выручку по дням от инсталла arpu_stat &lt;- conversion[, list(gross = sum(gross)), by = list(lifetime)] # считаем количество уникальных пользователей в июньской когорте arpu_stat[, total_users := installs[dt &lt; &#39;2022-07-01&#39;, uniqueN(user_pseudo_id)]] # сортируем и считаем кумулятивную выручку arpu_stat &lt;- arpu_stat[order(lifetime)] arpu_stat[, gross_cum := cumsum(gross)] # считаем кумулятивное ARPU arpu_stat[, cARPU := gross_cum / total_users] # рисуем plot_ly( arpu_stat, x = ~lifetime, y = ~cARPU, type = &#39;scatter&#39;, mode=&#39;lines&#39; ) %&gt;% layout( title = &#39;Cumulative ARPU, installs in June&#39;, yaxis = list(rangemode = &#39;tozero&#39;) ) %&gt;% config(displayModeBar = FALSE) Полезные материалы Основные метрики мобильных приложений Очень обзорный материал от devtodev. Есть неплохой блок по метрикам монетизации. Домашнее задание level 1 (IATYTD) Внимательно разберите материалы конспекта. level 2 (HNTR) Постройте график накопительной конверсии в когорте июньских пользователей с разбивкой по источнику пользователей. level 3 (N) Посчитайте по каждой платформе динамику метрики конверсию в платящих в день инсталла. На графике на оси OX должна быть дата инсталла, на оси OY – значение конверсии в день инсталла. Делать аналогично динамике ретеншена первого дня. level 4 (UV) Постройте и нарисуйте структуру накопительного ARPU для июньских пользователей в зависимости оттого, какие offer_type покупали пользователи. Таким образом мы можем понять, какая товарная категория делает наибольший вклад в кумулятивное ARPU. ИЛИ Постройте график накопительного ARPU в когорте июньских пользователей с разбивкой по источнику пользователей. level 5 (N) Посчитайте по каждой платформе динамику ARPU 0, 1, 7 и 30 дней (сколько в среднем заплатили пользователи когорты в день инсталла, за 0 и 1 дни жизни в приложении, за первые 7 дней жизни, за первые 30 дней жизни в приложении). На графике на оси OX должна быть дата инсталла, на оси OY – значение ARPU, с разбивкой, по какому количеству дней от инсталла мы это считаем Делать аналогично динамике ретеншена, я показывал на занятии про ретеншен как раз близкое решение. "],["c6_monetization.html", "Метрики монетизации pt.3 Запись занятия Код занятия на Python Разбор домашнего задания Метрики монетизации ARPDAU Paying share Воронка платежей Домашнее задание", " Метрики монетизации pt.3 Запись занятия Код занятия на Python https://colab.research.google.com/drive/1P36fEEJQHb-q5yKR9ieywopqd2USJ39b Разбор домашнего задания Датасеты: library(data.table) library(plotly) # импортируем данные installs &lt;- fread(&#39;https://gitlab.com/hse_mar/mar211f/-/raw/main/data/installs.csv&#39;) payments &lt;- fread(&#39;https://gitlab.com/hse_mar/mar211f/-/raw/main/data/payments_custom.csv&#39;) # делаем рыбу, чтобы учесть потерянные дни, в которых не было платежей arpu_fish &lt;- data.table( dt = seq(as.Date(&#39;2022-06-01&#39;), as.Date(&#39;2022-07-31&#39;), by = 1) ) arpu_fish &lt;- arpu_fish[, list(lifetime = 0:30), by = dt] # корректируем медиасорсы installs[media_source %in% c(&#39;organic&#39;, &#39;other&#39;) | is.na(media_source), media_source := &#39;organic&#39;] level 2 (HNTR) Постройте график накопительной конверсии в когорте июньских пользователей с разбивкой по источнику пользователей. # к платежам присоединяем дату инсталла и источник трафика conversion &lt;- merge( payments, installs[, list(user_pseudo_id, media_source, dt)], by = &#39;user_pseudo_id&#39;, all.x = TRUE ) # берем июньскую когорту и ограничиваем даты лайфтайма conversion[, lifetime := pay_dt - dt] conversion &lt;- conversion[dt &lt; &#39;2022-07-01&#39;] conversion &lt;- conversion[lifetime &gt;= 0 &amp; lifetime &lt;= 30] # беру минимальный день от инсталла # это будет день первого платежа conversion_stat &lt;- conversion[, list(lifetime = min(lifetime)), by = list(user_pseudo_id, media_source)] # считаю количество пользователей, которые сделали платеж на этот день conversion_stat &lt;- conversion_stat[, list(new_payers = uniqueN(user_pseudo_id)), by = list(media_source, lifetime)] # считаю, сколько всего было пользователей в когорте # conversion_stat[, total_users := installs[dt &lt; &#39;2022-07-01&#39;, uniqueN(user_pseudo_id)]] conversion_stat &lt;- merge( installs[dt &lt; &#39;2022-07-01&#39;, list(total_users = uniqueN(user_pseudo_id)), by = media_source], conversion_stat, by = &#39;media_source&#39;, all.x = TRUE ) # сортирую и считаю накопительное количество пользователей, которые сделали # первый платеж в этот день от инсталла conversion_stat &lt;- conversion_stat[order(media_source, lifetime)] conversion_stat[, new_payers_cum := cumsum(new_payers), by = media_source] # считаю накопительную конверсию в платящих conversion_stat[, cum_conversion := new_payers_cum / total_users] # рисую plot_ly( conversion_stat, x = ~lifetime, y = ~cum_conversion, type = &#39;scatter&#39;, mode=&#39;lines&#39;, color = ~media_source ) %&gt;% layout( title = &#39;Накопительная конверсия в зависимости от источников трафика&#39;, yaxis = list(rangemode = &#39;tozero&#39;) ) %&gt;% config(displayModeBar = FALSE) level 3 (N) Посчитайте динамику метрики конверсию в платящих в дни 0, 3, 7, 30 от инсталла. На графике на оси OX должна быть дата инсталла, на оси OY – значение конверсии в день инсталла. Делать аналогично динамике ретеншена первого дня. # Посчитайте по каждой платформе динамику метрики конверсии в платящих в день инсталла. 0, 3, 7, 30 # На графике на оси OX должна быть дата инсталла, на оси OY – значение конверсии в день инсталла. # Делать аналогично динамике ретеншена первого дня. conversion_dyn &lt;- merge( payments, installs[, list(user_pseudo_id, media_source, dt)], by = &#39;user_pseudo_id&#39;, all.x = TRUE ) conversion_dyn &lt;- conversion_dyn[!is.na(dt)] # берем июньскую когорту и ограничиваем даты лайфтайма conversion_dyn[, lifetime := pay_dt - dt] # это будет день первого платежа conversion_dyn_stat &lt;- conversion_dyn[, list(lifetime = min(lifetime)), by = list(user_pseudo_id, dt)] # считаю количество пользователей, которые сделали платеж на этот день conversion_dyn_stat &lt;- conversion_dyn_stat[, list(new_payers = uniqueN(user_pseudo_id)), by = list(dt, lifetime)] # присоединяем рыбу conversion_dyn_stat &lt;- merge(arpu_fish, conversion_dyn_stat, by = c(&#39;dt&#39;, &#39;lifetime&#39;), all.x = TRUE) # считаю, сколько всего было пользователей в когорте # conversion_stat[, total_users := installs[dt &lt; &#39;2022-07-01&#39;, uniqueN(user_pseudo_id)]] conversion_dyn_stat &lt;- merge( installs[, list(total_users = uniqueN(user_pseudo_id)), by = dt], conversion_dyn_stat, by = &#39;dt&#39;, all.x = TRUE ) # сортирую и считаю накопительное количество пользователей, которые сделали # первый платеж в этот день от инсталла conversion_dyn_stat &lt;- conversion_dyn_stat[order(dt, lifetime)] conversion_dyn_stat[is.na(new_payers), new_payers := 0] conversion_dyn_stat[, new_payers_cum := cumsum(new_payers), by = dt] # считаю накопительную конверсию в платящих conversion_dyn_stat[, cum_conversion := new_payers_cum / total_users] # рисую plot_ly( conversion_dyn_stat[lifetime %in% c(0, 3, 7, 30)], x = ~dt, y = ~cum_conversion, type = &#39;scatter&#39;, mode=&#39;lines&#39;, color = ~as.character(lifetime) ) %&gt;% layout( title = &#39;Накопительная конверсия в дневных когортах&#39;, yaxis = list(rangemode = &#39;tozero&#39;) ) %&gt;% config(displayModeBar = FALSE) Посчитайте по каждой платформе динамику метрики конверсию в платящих в день инсталла. На графике на оси OX должна быть дата инсталла, на оси OY – значение конверсии в день инсталла. Делать аналогично динамике ретеншена первого дня. conversion_dyn &lt;- merge( payments, installs[, list(user_pseudo_id, platform, dt)], by = c(&#39;user_pseudo_id&#39;, &#39;platform&#39;), all.x = TRUE ) conversion_dyn &lt;- conversion_dyn[!is.na(dt)] # берем июньскую когорту и ограничиваем даты лайфтайма conversion_dyn[, lifetime := pay_dt - dt] # это будет день первого платежа conversion_dyn_stat &lt;- conversion_dyn[, list(lifetime = min(lifetime)), by = list(user_pseudo_id, dt, platform)] # считаю количество пользователей, которые сделали платеж на этот день conversion_dyn_stat &lt;- conversion_dyn_stat[, list(new_payers = uniqueN(user_pseudo_id)), by = list(platform, dt, lifetime)] conversion_dyn_stat &lt;- merge(arpu_fish, conversion_dyn_stat, by = c(&#39;dt&#39;, &#39;lifetime&#39;), all.x = TRUE) # считаю, сколько всего было пользователей в когорте # conversion_stat[, total_users := installs[dt &lt; &#39;2022-07-01&#39;, uniqueN(user_pseudo_id)]] conversion_dyn_stat &lt;- merge( installs[, list(total_users = uniqueN(user_pseudo_id)), by = list(platform, dt)], conversion_dyn_stat, by = c(&#39;dt&#39;, &#39;platform&#39;), all.x = TRUE ) # сортирую и считаю накопительное количество пользователей, которые сделали # первый платеж в этот день от инсталла conversion_dyn_stat &lt;- conversion_dyn_stat[order(platform, dt, lifetime)] conversion_dyn_stat[is.na(new_payers), new_payers := 0] conversion_dyn_stat[, new_payers_cum := cumsum(new_payers), by = list(platform, dt)] # считаю накопительную конверсию в платящих conversion_dyn_stat[, cum_conversion := new_payers_cum / total_users] # рисую plot_ly( conversion_dyn_stat[lifetime == 0], x = ~dt, y = ~cum_conversion, type = &#39;scatter&#39;, mode=&#39;lines&#39;, color = ~platform ) %&gt;% layout( title = &#39;Динамика конверсии в платящих в дневных когортах в день инсталла&#39;, yaxis = list(rangemode = &#39;tozero&#39;) ) %&gt;% config(displayModeBar = FALSE) level 4 (UV) Постройте и нарисуйте структуру накопительного ARPU для июньских пользователей в зависимости оттого, какие offer_type покупали пользователи. Таким образом мы можем понять, какая товарная категория делает наибольший вклад в кумулятивное ARPU. ИЛИ Постройте график накопительного ARPU в когорте июньских пользователей с разбивкой по источнику пользователей. # к платежам присоединяем дату инсталла и источник трафика arpu_june &lt;- merge( payments, installs[, list(user_pseudo_id, media_source, dt)], by = &#39;user_pseudo_id&#39;, all.x = TRUE ) # берем июньскую когорту и ограничиваем даты лайфтайма arpu_june[, lifetime := pay_dt - dt] arpu_june &lt;- conversion[dt &lt; &#39;2022-07-01&#39;] arpu_june &lt;- arpu_june[lifetime &gt;= 0 &amp; lifetime &lt;= 30] # считаем деньги, которые платили в определенный день от инстала arpu_june_stat &lt;- arpu_june[, list(gross = sum(gross)), by = list(lifetime, offer_type)] # считаю, сколько всего было пользователей в когорте arpu_june_stat[, total_users := installs[dt &lt; &#39;2022-07-01&#39;, uniqueN(user_pseudo_id)]] # сортирую и считаю накопительную сумму денег, которую заплатили пользователи arpu_june_stat &lt;- arpu_june_stat[order(offer_type, lifetime)] arpu_june_stat[, gross_cum := cumsum(gross), by = offer_type] # считаю накопительную конверсию в платящих arpu_june_stat[, cum_ARPU := gross_cum / total_users] # рисую plot_ly( arpu_june_stat, x = ~lifetime, y = ~cum_ARPU, type = &#39;scatter&#39;, mode=&#39;none&#39;, stackgroup =&#39;one&#39;, color = ~offer_type ) %&gt;% layout( title = &#39;Накопительное ARPU по категориям&#39;, yaxis = list(rangemode = &#39;tozero&#39;) ) %&gt;% config(displayModeBar = FALSE) level 5 (N) Посчитайте по каждой платформе динамику ARPU 0, 1, 7 и 30 дней (сколько в среднем заплатили пользователи когорты в день инсталла, за 0 и 1 дни жизни в приложении, за первые 7 дней жизни, за первые 30 дней жизни в приложении). На графике на оси OX должна быть дата инсталла, на оси OY – значение ARPU, с разбивкой, по какому количеству дней от инсталла мы это считаем Делать аналогично динамике ретеншена, я показывал на занятии про ретеншен как раз близкое решение. arpu_dyn &lt;- merge( payments, installs[, list(user_pseudo_id, platform, dt)], by = c(&#39;user_pseudo_id&#39;, &#39;platform&#39;), all.x = TRUE ) # удаляю пользователей, которые пришли раньше июня arpu_dyn &lt;- conversion_dyn[!is.na(dt)] arpu_dyn[, lifetime := pay_dt - dt] arpu_dyn_stat &lt;- arpu_dyn[, list(gross = sum(gross)), by = list(dt, lifetime)] # присоединяю рыбу arpu_dyn_stat &lt;- merge(arpu_fish, arpu_dyn_stat, by = c(&#39;dt&#39;, &#39;lifetime&#39;), all.x = TRUE) # считаю, сколько всего было пользователей в когорте # conversion_stat[, total_users := installs[dt &lt; &#39;2022-07-01&#39;, uniqueN(user_pseudo_id)]] arpu_dyn_stat &lt;- merge( installs[, list(total_users = uniqueN(user_pseudo_id)), by = list(dt)], arpu_dyn_stat, by = c(&#39;dt&#39;), all.x = TRUE ) # сортирую и считаю накопительный гросс arpu_dyn_stat &lt;- arpu_dyn_stat[order(dt, lifetime)] arpu_dyn_stat[is.na(gross), gross := 0] arpu_dyn_stat[, gross_cum := cumsum(gross), by = list(dt)] # считаю накопительную конверсию в платящих arpu_dyn_stat[, cum_ARPU := gross_cum / total_users] # рисую plot_ly( arpu_dyn_stat[lifetime %in% c(0, 3, 7, 30)], x = ~dt, y = ~cum_ARPU, type = &#39;scatter&#39;, mode=&#39;lines&#39;, color = ~as.character(lifetime) ) %&gt;% layout( title = &#39;Динамика накопительного ARPU дневных когорт&#39;, yaxis = list(rangemode = &#39;tozero&#39;) ) %&gt;% config(displayModeBar = FALSE) Метрики монетизации Для июньской когорты, с разбивкой по платформе посчитать: количество пользователей количество платящих пользователей конверсия гросс арпу арппу средний размер платежа (гросс / количество платежей) среднее количество платежей на пользователя (количество платежей / количество платящих) Все в окне 30 дней от инсталла. installs_june &lt;- installs[dt &lt; &#39;2022-07-01&#39;] installs_june_stat &lt;- installs_june[, list(total_users = uniqueN(user_pseudo_id)), by = platform] payments_june &lt;- merge( installs_june[, list(user_pseudo_id, dt)], payments, by = &#39;user_pseudo_id&#39;, all = FALSE ) payments_june[, lifetime := pay_dt - dt] payments_june &lt;- payments_june[lifetime &lt;= 30] payments_june_stat &lt;- payments_june[, list( payers_30 = uniqueN(user_pseudo_id), gross_30 = sum(gross), n_transactions_30 = length(ts) ), by = platform] users_june_stat &lt;- merge( installs_june_stat, payments_june_stat, by = &#39;platform&#39;, all.x = TRUE ) users_june_stat[, gross_30 := round(gross_30)] users_june_stat[, Conversion_30 := paste0(round(payers_30 / total_users * 100, 1), &#39;%&#39;)] users_june_stat[, ARPU_30 := round(gross_30 / total_users, 3)] users_june_stat[, ARPPU_30 := round(gross_30 / payers_30, 3)] users_june_stat[, Av.Check_30 := round(gross_30 / n_transactions_30, 1)] users_june_stat[, Av.Purchases_30 := round(n_transactions_30 / payers_30, 1)] users_june_stat ## Key: &lt;platform&gt; ## platform total_users payers_30 gross_30 n_transactions_30 Conversion_30 ## &lt;char&gt; &lt;int&gt; &lt;int&gt; &lt;num&gt; &lt;int&gt; &lt;char&gt; ## 1: ANDROID 77770 1143 25452 3376 1.5% ## 2: IOS 33010 1458 65402 7346 4.4% ## ARPU_30 ARPPU_30 Av.Check_30 Av.Purchases_30 ## &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; ## 1: 0.327 22.268 7.5 3 ## 2: 1.981 44.857 8.9 5 ARPDAU Некогортная метрика – сколько в среднем приносит каждый зашедший в этот день пользователь. Обычно используется на дашбордах для мониторинга, какие сегменты пользователей как платят. ARPDAU = revenue / DAU Paying share Еще одна некогортная метрика – какая доля платящих среди зашедших в этот день. Также используется для мониторинга. Paying share = Payers / DAU Воронка платежей Доля пользователей, которые сделали второй, третий и т.д. платеж. Нужна для понимания, совершают ли пользователи повторные платежи. Дальше начинаются вопросы и интерпретации – почему не сделал второй платеж, и т. д. Алгоритм расчета: - берем таблицу платежей пользователя - сортируем по времени платежа - создаем новую колонку-счетчик (1, 2, 3) платежей для каждого пользователя - считаем, сколько пользователей сделало каждый номер платежа (т.е группируем по этому счетчику) - делим количество пользователей на сколько всего было пользователей, сделавших первый платеж (т.е. на значение из первой колонки) - рисуем барчартами опционально: лучше ограничить это все на лайфтайм (например, на 7 дней) и на количество платежей (например, 10, чтобы баров было не сильно много и график был читаемым) Как создать колонку-счетчик: # в R my_dt[, counter := 1:.N, by = uid] # в Python my_dt[&#39;counter&#39;] = my_dt.groupby(&#39;uid&#39;).cumcount() + 1 Домашнее задание level 1 (IATYTD) Внимательно разберите решения заданий (материалы конспекта). level 2 (HNTR) Рассчитайте табличку с метриками монетизации для июньской когорты. Сделайте разбивку по платформам. Попробуйте проинтерпретировать результаты. level 3 (HMP) Рассчитайте табличку с метриками монетизации для июньской и июльской когорт (должно быть две строки в табличке, отдельно на каждую когорту). Выберите правильный период лайфтайма. Попробуйте проинтерпретировать результаты. level 4 (UV) Постройте воронку платежей для июньской когорты. Сделайте разбивку по платформам. Попробуйте проинтерпретировать результаты. level 5 (N) Постройте графики ARPDAU и Paying Share. Для этого вам понадобится табличка логинов (https://gitlab.com/hse_mar/mar211f/-/raw/main/data/dau.csv). Сделайте эти метрики в разбивке по тому, как давно пользователи пришли в приложение: группа 1: 0 дней с инсталла группа 2: 1-7 дней с момента инсталла группа 3: 8-28 дней с инсталла группа 4: более 28 дней с инсталла "],["c7_monetization.html", "Метрики монетизации pt.4 Запись занятия Код занятия на Python Разбор домашнего задания", " Метрики монетизации pt.4 Запись занятия Код занятия на Python https://colab.research.google.com/drive/1V4x-LdknR1vVhgrwCIvzsQjHpN1xmOrj Разбор домашнего задания Датасеты: library(data.table) library(plotly) Sys.setlocale(&#39;LC_ALL&#39;, &#39;en_US.UTF-8&#39;) ## [1] &quot;LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=en_US.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=ru_RU.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=ru_RU.UTF-8;LC_IDENTIFICATION=C&quot; # импортируем данные installs &lt;- fread(&#39;https://gitlab.com/hse_mar/mar211f/-/raw/main/data/installs.csv&#39;) payments &lt;- fread(&#39;https://gitlab.com/hse_mar/mar211f/-/raw/main/data/payments_custom.csv&#39;) # делаем рыбу, чтобы учесть потерянные дни, в которых не было платежей arpu_fish &lt;- data.table( dt = seq(as.Date(&#39;2022-06-01&#39;), as.Date(&#39;2022-07-31&#39;), by = 1) ) arpu_fish &lt;- arpu_fish[, list(lifetime = 0:30), by = dt] # корректируем медиасорсы installs[media_source %in% c(&#39;organic&#39;, &#39;other&#39;) | is.na(media_source), media_source := &#39;organic&#39;] level 2 (HNTR) Рассчитайте табличку с метриками монетизации для июньской когорты. Сделайте разбивку по платформам. Попробуйте проинтерпретировать результаты. # выделяем инсталлы в июне installs_june &lt;- installs[dt &gt;= &#39;2022-06-01&#39; &amp; dt &lt; &#39;2022-07-01&#39;] installs_june_stat &lt;- installs_june[, list(total_users = uniqueN(user_pseudo_id)), by = list(media_source)] installs_june_stat ## media_source total_users ## &lt;char&gt; &lt;int&gt; ## 1: applovin_int 36714 ## 2: organic 43070 ## 3: unityads_int 21932 ## 4: googleadwords_int 7767 ## 5: Facebook Ads 1297 # к платежам присоединяем дату инсталла и источник трафика payments_june &lt;- merge( installs_june[, list(user_pseudo_id, media_source, dt)], payments, by = &#39;user_pseudo_id&#39;, all = FALSE ) # берем июньскую когорту и ограничиваем даты лайфтайма payments_june[, lifetime := pay_dt - dt] payments_june &lt;- payments_june[lifetime &gt;= 0 &amp; lifetime &lt;= 30] payments_june_stat &lt;- payments_june[, list( payers_30 = uniqueN(user_pseudo_id), gross_30 = sum(gross), n_transactions_30 = length(ts) ), by = list(media_source)] payments_june_stat ## media_source payers_30 gross_30 n_transactions_30 ## &lt;char&gt; &lt;int&gt; &lt;num&gt; &lt;int&gt; ## 1: organic 1000 39958.64 4444 ## 2: unityads_int 262 6061.02 974 ## 3: applovin_int 1120 38554.59 4583 ## 4: Facebook Ads 53 914.41 103 ## 5: googleadwords_int 161 4392.92 518 users_june_stat = merge( installs_june_stat, payments_june_stat, by = &#39;media_source&#39;, all.x = TRUE ) users_june_stat[, gross_30 := round(gross_30)] users_june_stat[, Conversion_30 := paste0(round(payers_30 * 100 / total_users, 1), &#39;%&#39;)] users_june_stat[, ARPU_30 := round(gross_30 / total_users, 3)] users_june_stat[, ARPPU_30 := round(gross_30 / payers_30, 3)] users_june_stat[, Av.Check_30 := round(gross_30 / n_transactions_30, 1)] users_june_stat[, Av.Purchases_30 := round(n_transactions_30 / payers_30, 1)] users_june_stat[, CPI := c(0.5, 2, .9, NA, 0.3)] users_june_stat[, RoAS := round(ARPU_30 / CPI, 3)] kableExtra::kable(users_june_stat) media_source total_users payers_30 gross_30 n_transactions_30 Conversion_30 ARPU_30 ARPPU_30 Av.Check_30 Av.Purchases_30 CPI RoAS Facebook Ads 1297 53 914 103 4.1% 0.705 17.245 8.9 1.9 0.5 1.410 applovin_int 36714 1120 38555 4583 3.1% 1.050 34.424 8.4 4.1 2.0 0.525 googleadwords_int 7767 161 4393 518 2.1% 0.566 27.286 8.5 3.2 0.9 0.629 organic 43070 1000 39959 4444 2.3% 0.928 39.959 9.0 4.4 NA NA unityads_int 21932 262 6061 974 1.2% 0.276 23.134 6.2 3.7 0.3 0.920 level 3 (HMP) Рассчитайте табличку с метриками монетизации для июньской и июльской когорт (должно быть две строки в табличке, отдельно на каждую когорту). Выберите правильный период лайфтайма. Попробуйте проинтерпретировать результаты. installs_jj &lt;- installs[dt &lt; &#39;2022-07-25&#39;] installs_jj[, month := strftime(dt, &#39;%B&#39;)] installs_jj_stat &lt;- installs_jj[, list(total_users = uniqueN(user_pseudo_id)), by = list(month)] # к платежам присоединяем дату инсталла и источник трафика payments_jj &lt;- merge( installs_jj[, list(user_pseudo_id, month, dt)], payments, by = &#39;user_pseudo_id&#39;, all = FALSE ) # берем июньскую когорту и ограничиваем даты лайфтайма payments_jj[, lifetime := pay_dt - dt] payments_jj &lt;- payments_jj[lifetime &gt;= 0 &amp; lifetime &lt;= 7] payments_jj_stat &lt;- payments_jj[, list( payers_7 = uniqueN(user_pseudo_id), gross_7 = sum(gross), n_transactions_7 = length(ts) ), by = list(month)] users_jj_stat = merge( installs_jj_stat, payments_jj_stat, by = &#39;month&#39;, all.x = TRUE ) users_jj_stat[, gross_7 := round(gross_7)] users_jj_stat[, Conversion_7 := paste0(round(payers_7 * 100 / total_users, 1), &#39;%&#39;)] users_jj_stat[, ARPU_7 := round(gross_7 / total_users, 3)] users_jj_stat[, ARPPU_7 := round(gross_7 / payers_7, 3)] users_jj_stat[, Av.Check_7 := round(gross_7 / n_transactions_7, 1)] users_jj_stat[, Av.Purchases_7 := round(n_transactions_7 / payers_7, 1)] kableExtra::kable(users_jj_stat) month total_users payers_7 gross_7 n_transactions_7 Conversion_7 ARPU_7 ARPPU_7 Av.Check_7 Av.Purchases_7 July 11843 217 4582 757 1.8% 0.387 21.115 6.1 3.5 June 110780 2059 42518 5217 1.9% 0.384 20.650 8.1 2.5 level 4 (UV) Постройте воронку платежей для июньской когорты. Сделайте разбивку по платформам. Попробуйте проинтерпретировать результаты. # выше мы уже делали вычисление дней от инсталла и фильтрацию на 30 дней payments_june &lt;- payments_june[order(user_pseudo_id, ts)] payments_june[, purchase_number := seq_len(.N), by = user_pseudo_id] # считаем, сколько пользователей сделало платеж с этим номером payments_funnel &lt;- payments_june[, list(n_users = uniqueN(user_pseudo_id)), keyby = purchase_number] # считаем посчитать долю от всего пользователей, сделавших платеж (purchase_number == 1) payments_funnel[, total_payers := n_users[purchase_number == 1]] # если у нас есть группировка, то надо отдельно считать и мерджить по ключу # рисуем payments_funnel[, share := n_users / total_payers] plot_ly(payments_funnel[purchase_number &lt;= 10], x = ~purchase_number, y = ~share, type = &#39;bar&#39;) %&gt;% layout( title = &#39;Воронка платежей&#39; ) %&gt;% config(displayModeBar = FALSE) Воронки можно считать не от первого шага, а от предыдущего. В некоторых случаях это удобнее и информативнее. # если хотим считать от предыдущего шага payments_funnel[, prev_users := shift(n_users, n = 1)] payments_funnel[, prev_share := n_users / prev_users] plot_ly(payments_funnel[purchase_number &lt;= 10], x = ~purchase_number, y = ~prev_share, type = &#39;bar&#39;) %&gt;% layout( title = &#39;Воронка платежей, доля от предыдущего&#39; ) %&gt;% config(displayModeBar = FALSE) ## Warning: Ignoring 1 observations Обе воронки сразу plot_ly(payments_funnel[purchase_number &lt;= 10], x = ~purchase_number, y = ~share, type = &#39;bar&#39;, name = &#39;% from payers&#39;) %&gt;% add_trace(y = ~prev_share, name = &#39;% from prev&#39;) %&gt;% layout( title = &#39;Воронка платежей&#39; ) %&gt;% config(displayModeBar = FALSE) ## Warning: Ignoring 1 observations "],["ux.html", "UX intro Запись занятия Полезные ссылки", " UX intro Запись занятия Полезные ссылки Customer Development и Custdev. Что это такое и в чем разница? Статья в блоге Олега Якубенкова. Телеграм-канал Юлии Кожуховой Канал о личном опыте маркетинговых и продуктовых исследований: нетривиальных случаях, труднодоступных аудиториях и работающих методах. Канал про полезное и вдохновляющее про исследования и исследователей от UX-команды Контура Регулярная подборка лучших постов про UX-исследования и смежных областей. Телеграм-сообщество UX REsearch. "],["homework-1.html", "Homework 1 Общие замечания Описание данных Задание 1 Задание 2 Задание 3 Задание 4", " Homework 1 Общие замечания Срок сдачи работы: 1 декабря 2024 включительно. Домашнее задание лучше выполнять в R или R + Rmarkdown. Если R и Rmarkdown у вас вызывают сомнения, можете прислать решение в виде R скрипта, где комментарии по работе должны быть в виде строк комментариев. Если вы работаете в Python - аналогично, меня устроит и .ipynb (Jupyter), и Google Colab, и .py. Если будете использовать Colab, то я скопирую ноутбук себе сразу после того, как вы мне пришлете ссылку. Если ни R, ни Python у вас не вызывают энтузиазма, и вы хотите как-то по-другому выполнять работу, напишите мне дополнительно. Свой файл с кодом решения назовите по структуре mar231_hw1_&lt;ваша фамилия латиницей&gt; и пришлите либо в личных сообщениях в телеграме, либо на почту upravitelev@gmail.com, в теме также укажите mar231_hw1_&lt;ваша фамилия латиницей&gt;. Старайтесь комментировать каждую значимую строчку кода (т. е., в которой происходит сложное или не очень прозрачное преобразование). Комментарии нужны, впервую очередь, для того, чтобы вы могли продемонстрировать, что понимаете, что и зачем делаете. Если некоторые операции однозначны и очевидны, комментарии можно опустить. Соблюдайте гайд по стилю оформления кода и/или используйте автоформатирование RStudio (ctr+shift+A на выделенном коде для Win/*nix). Отсутствие комментариев, неопрятность и/или нечитаемость кода, несоблюдение конвенций гайда по стилю - на все это я буду обращать внимание и, в случае существенных помарок, снижать оценку. Для пишущих на Python – можете следовать этому же гайду, или PEP8, или любому другому стилю форматирования. Главное, чтобы было аккуратно и прозрачно. Выполняйте задание самостоятельно. Если у меня возникнут затруднения в объективной оценке, то договоримся о созвоне и я попрошу прокомментировать то или иное решение, или же дам небольшое задание из аналогичных, чтобы сравнить стиль решения и рассуждений. Если при выполнении задания все же возникнут какие-то вопросы - можете спросить меня (все вопросы в телеграме - либо в личке, либо в канале #discussion). Не гарантирую, что отвечу максимально подробно, но дать минимальную подсказку или прояснить неясность задания постараюсь. Имейте в виду, что данные сгенерированы (то есть, ненастоящие), поэтому в них могут быть артефакты или странности. тем, кто был на занятии по sql, настоятельно рекомендую джойны и фильтрации делать средствами SQL. Описание данных users.csv - инсталлы пользователей, с указанием даты инсталла, канала привлечения пользователя, стоимости привлечения (CPI) и версии приложения. auth.csv - даты авторизаций пользователей (в какие даты пользователи заходили в приложение). onboarding.csv - логи прохождение пользователями ключевых этапов от первого старта приложения до первой покупки (нередко этот этап или его часть называют онбордингом). payments.csv - логи платежей пользователей, содержат дату и размер платежа. NB! Считайте, что последний день, когда пользователи могли заходить в приложение - 21 ноября. Задание 1 Нарисуйте и проинтерпретируйте график удержания пользователей в приложении, с учетом канала привлечения пользователей. Попробуйте объяснить / предположить причины такой динамики метрики удержания в первые три дня (lifetime в интервале 0-2) по каналам. Рекомендация: на барчарте или в таблице видно лучше, чем на линейном графике. Напишите, каким образом можно было бы проверить вашу гипотезу. Задание 2 У вас есть приложение (маркетплейс), 16 октября приложение обновили с версии 0.3 до версии 0.4. Необходимо оценить результаты обновления. Описание приложения, точек монетизации и изменений в версии дано ниже. Данные после 1 ноября – артефакт, на них можно не обращать внимание. Описание приложения Маркетплейс (ozon, беру, avito, юла, joom, aliexpress, ebay и подобные). Приложение бесплатно для покупателей, вся выручка идет с продавцов. Продавцы платят: долю от каждой продажи (безлимитное количество объявлений) или фиксированную плату за какое-то количество объявлений за использование некоторых инструментов, по выбору продавца: промоутинг объявления в топе выдачи на какое-то время (если купить, то при релевантном запросе объявление этого продавца на какое-то время будет в выдаче выше аналогичных объявлений других продавцов) за страховку сделки маркетплейсом (деньги на счету покупателя блокируются до получения товара) за возможность указать телефон в профиле продавца индивидуальное оформление объявлений (фон, рамка, эмодзи) Changelog (изменения в функционале и исправления ошибок): сделали отдельный интерфейс для телефонов и планшетов (различия в ориентации, расположении некоторых кнопок и проч) подключили курьерскую службу и точки доставки (доставкой занимается маркетплейс, а не продавец) добавили шаблоны объявлений для наиболее популярных товаров включили сортировку объявлений по дате последнего изменения поменяли систему для техподдержки (был сервис Zendesk, стал Helpshift) починили редкий баг в автосохранении черновиков объявлений добавили звонки/голосовую связь между пользователями размер приложения увеличился на 70Мб и составил 130Мб Задание Покажите на графике, как изменилась прибыль проекта после запуска новой версии (если сможете, отметьте вертикальной линией на графике дату выхода новой версии). Поэкспериментируйте, какой тип графика будет тут удобнее для восприятия. Проведите исследование и объясните причины такой динамики (подкрепите выводы графиками или таблицами). Также сформулируйте гипотезы, что из продуктовых изменений могло привести к таким эффектами. Данные после 1 ноября – артефакт, на них можно не обращать внимание и не включать в интепретацию. На графике можно их скрыть. Задание 3 Посчитайте основные монетизационные метрики (количество платящих, конверсию, прибыль, ARPU, ARPPU, средний чек и среднее количество платежей, средний CPI), представьте в виде таблицы. В идеале должно получится четыре строчки в таблице: на каждый канал и одна общая. По возможности, округляйте дроби до значимых знаков после запятой (3 для конверсии и arpu/arppu, 1 для среднего чека или ср.количества платежей и т.д.). Нарисуйте график LTV по каналам привлечения пользователей. Проинтерпретируйте график LTV, оцените перспективу окупаемости пользователей с разных рекламных площадок. Дайте рекомендации маркетингу и специалистам по закупке трафика. Задание 4 Нарисуйте воронку шагов онбординга (первый событий пользователя в приложении) по версиям. Сделайте выводы, сформулируйте рекомендации для команды разработки. Информация о новых особенностях версии 0.4 дана выше в задании 2. Смысл шагов: st01_appstart - запуск приложения st02_sdk - инициализация sdk Facebook, Appsflyer st03_authorization - получение с сервера данных о профиле пользователя st04_download - дозагрузка дополнительных материалов st05_main_window - отрисовка основного окна приложения (завершение процесса старта) st06_oboarding_start - начало онбординга (как работать с приложением) st07_oboarding_end - завершение онбординга st08_add_adv - пользователь добавил самостоятельно объявление st9_purchase - пользователь сделал платеж "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
